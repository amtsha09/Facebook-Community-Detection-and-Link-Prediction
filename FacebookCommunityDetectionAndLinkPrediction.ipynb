{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict, deque\n",
    "import copy\n",
    "import math\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bfs(graph, root, max_depth):\n",
    "    \"\"\"\n",
    "    Perform breadth-first search to compute the shortest paths from a root node to all\n",
    "    other nodes in the graph. \n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      root........The root node in the search graph (a string). We are computing\n",
    "                  shortest paths from this node to all others.\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      node2distances...dict from each node to the length of the shortest path from\n",
    "                       the root node\n",
    "      node2num_paths...dict from each node to the number of shortest paths from the\n",
    "                       root node that pass through this node.\n",
    "      node2parents.....dict from each node to the list of its parents in the search\n",
    "                       tree\n",
    "    \"\"\"\n",
    "    dq = deque()\n",
    "    node2distances = defaultdict(int)\n",
    "    node2num_paths = defaultdict(int)\n",
    "    node2parents = defaultdict(list)\n",
    "    visited = []\n",
    "    visited.append(root)\n",
    "    dq.append(root)\n",
    "    node2num_paths[root]=1\n",
    "    while dq:\n",
    "        parent = dq.popleft()\n",
    "        children = graph.neighbors(parent)\n",
    "        for child in children:\n",
    "            if node2distances[parent] < max_depth:\n",
    "                if child not in visited:\n",
    "                    visited.append(child)\n",
    "                    dq.append(child)\n",
    "                    node2distances[child] = node2distances[parent] + 1\n",
    "                if node2distances[child] == node2distances[parent] + 1:\n",
    "                    node2parents[child].append(parent)\n",
    "                    node2num_paths[child] = len(node2parents[child])\n",
    "\n",
    "    #temp = sorted((node, sorted(parents)) for node, parents in node2parents.items())\n",
    "    return node2distances, node2num_paths, node2parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bottom_up(root, node2distances, node2num_paths, node2parents):\n",
    "    \"\"\"\n",
    "    Compute the final step of the Girvan-Newman algorithm.\n",
    "\n",
    "    Params:\n",
    "      root.............The root node in the search graph (a string). We are computing\n",
    "                       shortest paths from this node to all others.\n",
    "      node2distances...dict from each node to the length of the shortest path from\n",
    "                       the root node\n",
    "      node2num_paths...dict from each node to the number of shortest paths from the\n",
    "                       root node that pass through this node.\n",
    "      node2parents.....dict from each node to the list of its parents in the search\n",
    "                       tree\n",
    "    Returns:\n",
    "      A dict mapping edges to credit value. \n",
    "      \n",
    "    \"\"\"\n",
    "    node2dist = sorted(node2distances.items(), key=lambda x: -x[1])\n",
    "    edgeOfNode = defaultdict(float)\n",
    "\n",
    "\n",
    "    for i in node2parents:\n",
    "        edgeOfNode[i] = 1/node2num_paths[i]\n",
    "\n",
    "    for i,j in node2dist:\n",
    "        for k in node2parents[i]:\n",
    "            edgeOfNode[k]=edgeOfNode[k]+edgeOfNode[i]\n",
    "    edgeOfNode.pop(root)\n",
    "\n",
    "    edgeDict = {}\n",
    "    for i,j in node2dist:\n",
    "        for k in node2parents[i]:\n",
    "            edgeDict[tuple(sorted([i,k]))] = edgeOfNode[i]\n",
    "\n",
    "    return edgeDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def approximate_betweenness(graph, max_depth):\n",
    "    \"\"\"\n",
    "    Compute the approximate betweenness of each edge, using max_depth to reduce\n",
    "    computation time in breadth-first search.\n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      A dict mapping edges to betweenness. \n",
    "      \n",
    "    \"\"\"\n",
    "    ApproxDict = defaultdict()\n",
    "    for root in graph.nodes():\n",
    "        node2distances, node2num_paths, node2parents = bfs(graph, root, max_depth )\n",
    "        bottomDict = bottom_up(root, node2distances, node2num_paths, node2parents)\n",
    "        for edge in bottomDict:\n",
    "            if edge in ApproxDict:\n",
    "                ApproxDict[edge] = ApproxDict[edge]+bottomDict[edge]\n",
    "            else:\n",
    "                ApproxDict[edge]= bottomDict[edge]\n",
    "\n",
    "    for i in ApproxDict:\n",
    "        ApproxDict[i] = ApproxDict[i]/2\n",
    "\n",
    "    return ApproxDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_girvan_newman(graph, max_depth):\n",
    "    \"\"\"\n",
    "    Use approximate_betweenness implementation to partition a graph.\n",
    "    Compute the approximate betweenness of all edges, and remove\n",
    "    them until multiple comonents are created.\n",
    "\n",
    "    Params:\n",
    "      graph.......A networkx Graph\n",
    "      max_depth...An integer representing the maximum depth to search.\n",
    "\n",
    "    Returns:\n",
    "      A list of networkx Graph objects, one per partition.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    components = [c for c in nx.connected_component_subgraphs(graph)]\n",
    "    copied_graph = graph.copy()\n",
    "    edge_to_remove = sorted(approximate_betweenness(copied_graph, max_depth).items(), key=lambda x: (-x[1],x[0]))\n",
    "    while len(components) == 1:\n",
    "        copied_graph.remove_edge(*edge_to_remove[count][0])\n",
    "        components = [c for c in nx.connected_component_subgraphs(copied_graph)]\n",
    "        count+=1\n",
    "\n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_subgraph(graph, min_degree):\n",
    "    \"\"\"Return a subgraph containing nodes whose degree is\n",
    "    greater than or equal to min_degree.\n",
    "    We'll use this in the main method to prune the original graph.\n",
    "\n",
    "    Params:\n",
    "      graph........a networkx graph\n",
    "      min_degree...degree threshold\n",
    "    Returns:\n",
    "      a networkx graph, filtered as defined above.\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    subgraph = graph.copy()\n",
    "    for node in subgraph.degree().items():\n",
    "        if node[1] < min_degree:\n",
    "            subgraph.remove_node(node[0])\n",
    "    return subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def volume(nodes, graph):\n",
    "    \"\"\"\n",
    "    Compute the volume for a list of nodes, which\n",
    "    is the number of edges in `graph` with at least one end in\n",
    "    nodes.\n",
    "    Params:\n",
    "      nodes...a list of strings for the nodes to compute the volume of.\n",
    "      graph...a networkx graph\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for edge in graph.edges():\n",
    "        if edge[0] in nodes:\n",
    "            count +=1\n",
    "        elif edge[1] in nodes:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(S, T, graph):\n",
    "    \"\"\"\n",
    "    Compute the cut-set of the cut (S,T), which is\n",
    "    the set of edges that have one endpoint in S and\n",
    "    the other in T.\n",
    "    Params:\n",
    "      S.......set of nodes in first subset\n",
    "      T.......set of nodes in second subset\n",
    "      graph...networkx graph\n",
    "    Returns:\n",
    "      An int representing the cut-set.\n",
    "\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for edge in graph.edges():\n",
    "        if edge[0] in S and edge[1] in T or edge[0] in T and edge[1] in S:\n",
    "            count += 1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_cut(S, T, graph):\n",
    "    \"\"\"\n",
    "    The normalized cut value for the cut S/T.\n",
    "    Params:\n",
    "      S.......set of nodes in first subset\n",
    "      T.......set of nodes in second subset\n",
    "      graph...networkx graph\n",
    "    Returns:\n",
    "      An float representing the normalized cut value\n",
    "\n",
    "    \"\"\"\n",
    "    volS = volume(S, graph)\n",
    "    volT = volume(T, graph)\n",
    "    cutST = cut(S, T, graph)\n",
    "    NCV = (cutST/volS) + (cutST/volT)\n",
    "    return NCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_max_depths(graph, max_depths):\n",
    "    \"\"\"\n",
    "    In order to assess the quality of the approximate partitioning method\n",
    "    we've developed, we will run it with different values for max_depth\n",
    "    and see how it affects the norm_cut score of the resulting partitions.\n",
    "    Recall that smaller norm_cut scores correspond to better partitions.\n",
    "\n",
    "    Params:\n",
    "      graph........a networkx Graph\n",
    "      max_depths...a list of ints for the max_depth values to be passed\n",
    "                   to calls to partition_girvan_newman\n",
    "\n",
    "    Returns:\n",
    "      A list of (int, float) tuples representing the max_depth and the\n",
    "      norm_cut value obtained by the partitions returned by\n",
    "      partition_girvan_newman. See Log.txt for an example.\n",
    "    \"\"\"\n",
    "    smd = []\n",
    "    for depth in max_depths:\n",
    "        components = partition_girvan_newman(graph, depth)\n",
    "        S = components[0]\n",
    "        T = components[1]\n",
    "        ncv = norm_cut(S, T, graph)\n",
    "        smd.append((depth,ncv))\n",
    "    return smd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_training_graph(graph, test_node, n):\n",
    "    \"\"\"\n",
    "    To make a training graph, we need to remove n edges from the graph.\n",
    "    Remove the edges to the first n neighbors of\n",
    "    test_node, where the neighbors are sorted alphabetically.\n",
    "    \n",
    "    Params:\n",
    "      graph.......a networkx Graph\n",
    "      test_node...a string representing one node in the graph whose\n",
    "                  edges will be removed.\n",
    "      n...........the number of edges to remove.\n",
    "\n",
    "    Returns:\n",
    "      A *new* networkx Graph with n edges removed.\n",
    "\n",
    "   \n",
    "    \"\"\"\n",
    "    oldgraph = graph.copy()\n",
    "    li = sorted(graph.neighbors(test_node))\n",
    "    for i in li[:n]:\n",
    "        oldgraph.remove_edge(i,test_node)\n",
    "    return oldgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard(graph, node, k):\n",
    "    \"\"\"\n",
    "    Compute the k highest scoring edges to add to this node based on\n",
    "    the Jaccard similarity measure.\n",
    "\n",
    "    Params:\n",
    "      graph....a networkx graph\n",
    "      node.....a node in the graph (a string) to recommend links for.\n",
    "      k........the number of links to recommend.\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples in descending order of score representing the\n",
    "      recommended new edges. Ties are broken by\n",
    "      alphabetical order of the terminal node in the edge.\n",
    "   \n",
    "    \"\"\"\n",
    "    neighbors = set(graph.neighbors(node))\n",
    "    scores = []\n",
    "    for n in graph.nodes():\n",
    "        if node!=n and not graph.has_edge(node,n):\n",
    "            neighbors2 = set(graph.neighbors(n))\n",
    "            scores.append(((node,n), 1. * len(neighbors & neighbors2) / len(neighbors | neighbors2)))\n",
    "    return sorted(scores, key=lambda x: (-x[1],x[0][1]))[:k]\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def path_score(graph, root, k, beta):\n",
    "    \"\"\"\n",
    "    Compute a new link prediction scoring function based on the shortest\n",
    "    paths between two nodes.\n",
    "\n",
    "    Params:\n",
    "      graph....a networkx graph\n",
    "      root.....a node in the graph (a string) to recommend links for.\n",
    "      k........the number of links to recommend.\n",
    "      beta.....the beta parameter in the equation above.\n",
    "\n",
    "    Returns:\n",
    "      A list of tuples in descending order of score. Ties are broken by\n",
    "      alphabetical order of the terminal node in the edge.\n",
    "\n",
    "    \"\"\"\n",
    "    node2distances, node2num_ppaths, node2parents = bfs(graph, root, math.inf)\n",
    "    score = []\n",
    "    for n in graph.nodes():\n",
    "        if root!=n and not graph.has_edge(n,root):\n",
    "            score.append(((root, n), (beta ** node2distances[n]) * node2num_ppaths[n]))\n",
    "    return sorted(score, key = lambda x:(-x[1],x[0][1]))[:k]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(predicted_edges, graph):\n",
    "    \"\"\"\n",
    "    Return the fraction of the predicted edges that exist in the graph.\n",
    "\n",
    "    Args:\n",
    "      predicted_edges...a list of edges (tuples) that are predicted to\n",
    "                        exist in this graph\n",
    "      graph.............a networkx Graph\n",
    "\n",
    "    Returns:\n",
    "      The fraction of edges in predicted_edges that exist in the graph.\n",
    "\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for edg in predicted_edges:\n",
    "        if graph.has_edge(*edg):\n",
    "            count+=1\n",
    "    return count/len(predicted_edges)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_graph():\n",
    "    \"\"\" Read 'edges.txt.gz' into a networkx **undirected** graph.\n",
    "    Returns:\n",
    "      A networkx undirected graph.\n",
    "    \"\"\"\n",
    "    return nx.read_edgelist('edges.txt.gz', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    graph = read_graph()\n",
    "    print('graph has %d nodes and %d edges' %\n",
    "          (graph.order(), graph.number_of_edges()))\n",
    "    subgraph = get_subgraph(graph, 2)\n",
    "    print('subgraph has %d nodes and %d edges' %\n",
    "          (subgraph.order(), subgraph.number_of_edges()))\n",
    "\n",
    "    print('norm_cut scores by max_depth:')\n",
    "    print(score_max_depths(subgraph, range(1,5)))\n",
    "\n",
    "    clusters = partition_girvan_newman(subgraph, 3)\n",
    "    print('first partition: cluster 1 has %d nodes and cluster 2 has %d nodes' %\n",
    "          (clusters[0].order(), clusters[1].order()))\n",
    "    print('cluster 2 nodes:')\n",
    "    print(clusters[1].nodes())\n",
    "\n",
    "    test_node = 'Bill Gates'\n",
    "    train_graph = make_training_graph(subgraph, test_node, 5)\n",
    "    print('train_graph has %d nodes and %d edges' %\n",
    "          (train_graph.order(), train_graph.number_of_edges()))\n",
    "\n",
    "\n",
    "    jaccard_scores = jaccard(train_graph, test_node, 5)\n",
    "    print('\\ntop jaccard scores for Bill Gates:')\n",
    "    print(jaccard_scores)\n",
    "    print('jaccard accuracy=%g' %\n",
    "          evaluate([x[0] for x in jaccard_scores], subgraph))\n",
    "\n",
    "    path_scores = path_score(train_graph, test_node, k=5, beta=.1)\n",
    "    print('\\ntop path scores for Bill Gates for beta=.1:')\n",
    "    print(path_scores)\n",
    "    print('path accuracy for beta .1=%g' %\n",
    "          evaluate([x[0] for x in path_scores], subgraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
